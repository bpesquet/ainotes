{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f94d59",
   "metadata": {},
   "source": [
    "# CIFAR10\n",
    "\n",
    "## Objective\n",
    "\n",
    "Training models to associate images representing common objects with their class (multiclass classification).\n",
    "\n",
    "## Context\n",
    "\n",
    "The [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The classes are completely mutually exclusive. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "![CIFAR10 images](_images/cifar10.png)\n",
    "\n",
    "## Instructions and advice\n",
    "\n",
    "- Follow the main steps of a supervised ML project: data loading and exploring, data preparation, model training and evaluation.\n",
    "- Use the [PyTorch](https://pytorch.org) library for data loading and model training. If you are new to it, consider following its [official tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
    "- Don't forget to setup your environment by importing the necessary Python packages. Several helper functions (see below) have already been defined for you.\n",
    "- Regarding data preparation, bitmap images should be normalized. You can find an example [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#load-and-normalize-cifar10).\n",
    "- You may train and evaluate a standard MultiLayer Perceptron, using [this chapter](../ann.ipynb) as a blueprint. Warning: you will have to adapt the inputs of your network to the color images of the CIFAR10 dataset.\n",
    "- **Bonus**: train a convolutional neural network using [this chapter](../cnn.ipynb) as a blueprint. After training, compare its performance with the MLP results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ddb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "\n",
    "def plot_loss_acc(history):\n",
    "    \"\"\"Plot training loss and accuracy. Takes a Keras-like History object as parameter\"\"\"\n",
    "\n",
    "    loss_values = history[\"loss\"]\n",
    "    recorded_epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    ax1.plot(recorded_epochs, loss_values, \".--\", label=\"Training loss\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "\n",
    "    acc_values = history[\"acc\"]\n",
    "    ax2.plot(recorded_epochs, acc_values, \".--\", label=\"Training accuracy\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    final_loss = loss_values[-1]\n",
    "    final_acc = acc_values[-1]\n",
    "    fig.suptitle(\n",
    "        f\"Training loss: {final_loss:.5f}. Training accuracy: {final_acc*100:.2f}%\"\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def count_parameters(model, trainable=True):\n",
    "    \"\"\"Return the total number of (trainable) parameters for a model\"\"\"\n",
    "\n",
    "    return (\n",
    "        sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        if trainable\n",
    "        else sum(p.numel() for p in model.parameters())\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_images(data, labels, model=None):\n",
    "    \"\"\"Plot some images with either their true or predicted labels\"\"\"\n",
    "\n",
    "    figure = plt.figure(figsize=(10, 6))\n",
    "    cols, rows = 8, 4\n",
    "    for i in range(1, cols * rows + 1):\n",
    "        sample_idx = torch.randint(len(data), size=(1,)).item()\n",
    "        img, label = data[sample_idx]\n",
    "        figure.add_subplot(rows, cols, i)\n",
    "\n",
    "        # Title is either true or predicted label\n",
    "        if model is None:\n",
    "            title = labels[label]\n",
    "        else:\n",
    "            # Add a dimension (to match expected shape with batch size) and store image on device memory\n",
    "            x_img = img[None, :].to(device)\n",
    "            # Compute predicted label for image\n",
    "            # Even if the model outputs unormalized logits, argmax gives the predicted label\n",
    "            pred_label = model(x_img).argmax(dim=1).item()\n",
    "            title = f\"{labels[pred_label]}?\"\n",
    "        plt.title(title)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        img = img / 2 + 0.5  # unnormalize\n",
    "        npimg = np.transpose(img.cpu().detach().numpy(), (1, 2, 0))\n",
    "        plt.imshow(npimg, cmap=\"binary\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
